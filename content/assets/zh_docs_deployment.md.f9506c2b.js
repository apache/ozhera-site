import{_ as a,a as e,b as o,c as r,d as l,e as p,f as s,g as t,h as i,i as c,j as n,k as h,l as m,m as d,n as u,o as z,p as g,q as _,r as y,s as k,t as b,u as q,v as f,w as E,x as v,y as x,z as O,A as P,B as H,C as F,D as C,E as j,F as S}from"./chunks/ozhera-log-manager.039ef01c.js";import{_ as B,o as M,h as R,Q as N}from"./chunks/framework.d1267443.js";const Q="/images/ozhera-log-stream.jpg",U=JSON.parse('{"title":"部署文档","description":"","frontmatter":{"outline":{"level":[2,4]}},"headers":[],"relativePath":"zh/docs/deployment.md","filePath":"zh/docs/deployment.md"}'),w={name:"zh/docs/deployment.md"},A=N('<h1 id="部署文档" tabindex="-1">部署文档 <a class="header-anchor" href="#部署文档" aria-label="Permalink to &quot;部署文档&quot;">​</a></h1><h2 id="_1-部署说明" tabindex="-1">1.部署说明 <a class="header-anchor" href="#_1-部署说明" aria-label="Permalink to &quot;1.部署说明&quot;">​</a></h2><p>OzHera operator的作⽤是在k8s集群中的指定namespace下⼀键拉起⼀个ozhera平台。该⽂档适⽤于有⼀定k8s基础(PV、PVC、Service、Pod、Deployment、DaemonSet等)的研发/运维同学。</p><p>OzHera是⼀套企业级的可观测性平台，部署时复杂度⾮常⾼，部署前请认真阅读以下部署⽂档及相关的 <a href="https://mp.weixin.qq.com/s?__biz=MzkwMjQzMzMxMg==&amp;mid=2247483720&amp;idx=1&amp;sn=c38fca2d3e82de43ce22acad73a1be21&amp;chksm=c0a4de07f7d35711c5cba634c3833708db19fcc9303a50b77f8c1601831cac8e9520e3f32ff5&amp;token=1000658198&amp;lang=zh_CN#rd" target="_blank" rel="noreferrer">operator介绍视频</a>。</p><h2 id="_2-部署步骤" tabindex="-1">2.部署步骤 <a class="header-anchor" href="#_2-部署步骤" aria-label="Permalink to &quot;2.部署步骤&quot;">​</a></h2><div class="tip custom-block"><p class="custom-block-title">项目中位置</p><p>ozhera-all/ozhera-operator/ozhera-operator-server/src/main/resources/operator/</p></div><h3 id="_2-1-创建独立命名空间及账号" tabindex="-1">2.1 创建独⽴命名空间及账号 <a class="header-anchor" href="#_2-1-创建独立命名空间及账号" aria-label="Permalink to &quot;2.1 创建独⽴命名空间及账号&quot;">​</a></h3><ul><li>执⾏命令，⽣效auth yaml（默认会⽣成空间：ozhera-namespace，账号：admin-mone）</li></ul><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">kubectl</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">apply</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">-f</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">ozhera_operator_auth.yaml</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">kubectl</span><span style="color:#24292E;"> </span><span style="color:#032F62;">apply</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">-f</span><span style="color:#24292E;"> </span><span style="color:#032F62;">ozhera_operator_auth.yaml</span></span></code></pre></div><h3 id="_2-2-创建-ozhera-crd" tabindex="-1">2.2 创建 ozhera CRD <a class="header-anchor" href="#_2-2-创建-ozhera-crd" aria-label="Permalink to &quot;2.2 创建 ozhera CRD&quot;">​</a></h3><ul><li>执⾏命令，⽣效crd yaml</li></ul><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">kubectl</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">apply</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">-f</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">ozhera_operator_crd.yaml</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">kubectl</span><span style="color:#24292E;"> </span><span style="color:#032F62;">apply</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">-f</span><span style="color:#24292E;"> </span><span style="color:#032F62;">ozhera_operator_crd.yaml</span></span></code></pre></div><h3 id="_2-3-部署operator" tabindex="-1">2.3 部署operator <a class="header-anchor" href="#_2-3-部署operator" aria-label="Permalink to &quot;2.3 部署operator&quot;">​</a></h3><ul><li>执⾏命令，部署operator</li></ul><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">kubectl</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">apply</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">-f</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">ozhera_operator_deployment.yaml</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">kubectl</span><span style="color:#24292E;"> </span><span style="color:#032F62;">apply</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">-f</span><span style="color:#24292E;"> </span><span style="color:#032F62;">ozhera_operator_deployment.yaml</span></span></code></pre></div><ul><li>确保部署的operator⼯程端⼝7001，能够对外访问。ozhera部署需要在operator提供的对外⻚⾯上进⾏操作。默认例⼦中使⽤LoadBalancer⽅式对外暴露可访问的ip、port。如需使⽤其它⽅式请⾃⾏修改yaml。</li></ul><p><img src="'+a+'" alt="ozhera-operator-deployment.png"></p><h3 id="_2-4-operator⻚面操作" tabindex="-1">2.4 Operator⻚⾯操作 <a class="header-anchor" href="#_2-4-operator⻚面操作" aria-label="Permalink to &quot;2.4 Operator⻚⾯操作&quot;">​</a></h3><h4 id="_2-4-1-访问operator⻚面" tabindex="-1">2.4.1 访问operator⻚⾯ <a class="header-anchor" href="#_2-4-1-访问operator⻚面" aria-label="Permalink to &quot;2.4.1 访问operator⻚⾯&quot;">​</a></h4><p>如果是使⽤2.3步中LoadBalancer⽅式，请先找到&quot;ozhera-op-nginx&quot; service的对外ip。执⾏命令：</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">kubectl</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">get</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">service</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">-n=ozhera-namespace</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">kubectl</span><span style="color:#24292E;"> </span><span style="color:#032F62;">get</span><span style="color:#24292E;"> </span><span style="color:#032F62;">service</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">-n=ozhera-namespace</span></span></code></pre></div><p>找到ozhera-op-nginx对应的EXTERNAL-IP，默认访问地址：<code>http://EXTERNAL-IP:80/</code></p><p>可⻅如下界⾯：</p><p><img src="'+e+'" alt="operator-home-page.jpg"></p><h4 id="_2-4-2-operator元数据填写" tabindex="-1">2.4.2 operator元数据填写 <a class="header-anchor" href="#_2-4-2-operator元数据填写" aria-label="Permalink to &quot;2.4.2 operator元数据填写&quot;">​</a></h4><ul><li><p>name：ozhera-bootstrap</p><p>k8s⾃定义资源名称，保持默认值不变。</p></li><li><p>Namespace：ozhera-namespace</p><p>ozhera部署的独⽴空间，建议保持ozhera-namespace不变，如需改变请注意yaml全局变更。</p></li></ul><h4 id="_2-4-3-k8s访问方式确认" tabindex="-1">2.4.3 k8s访问⽅式确认 <a class="header-anchor" href="#_2-4-3-k8s访问方式确认" aria-label="Permalink to &quot;2.4.3 k8s访问⽅式确认&quot;">​</a></h4><p>该步骤是⽣成ozhera平台中需要对外开放⻚⾯的访问ip:port。当前只⽀持k8s的LoadBalancer、NodePort⽅式。默认会先尝试LB模式，如若不⽀持，则选择NodePort（如果NodePort的ip未开放对外访问，则需另起代理，建议集群开启LB）。</p><p><img src="'+o+'" alt="operator-interview1.jpg"><img src="'+r+'" alt="operator-interview2.jpg"></p><p>请记住ozhera.homepage.url，ozhera集群搭建完后，默认访问地址就是：<code>http://${ozhera.homepage.url}</code></p><h4 id="_2-4-4-集群配置" tabindex="-1">2.4.4 集群配置 <a class="header-anchor" href="#_2-4-4-集群配置" aria-label="Permalink to &quot;2.4.4 集群配置&quot;">​</a></h4><p><strong>k8s-serviceType请勿修改</strong></p><p><img src="'+l+'" alt="operator-service-type.jpg"></p><h5 id="ozhera-mysql" tabindex="-1">OzHera-mysql <a class="header-anchor" href="#ozhera-mysql" aria-label="Permalink to &quot;OzHera-mysql&quot;">​</a></h5><p>⽬的是选择⼀个ozhera可⽤的mysql数据库。</p><ul><li><p>如果需要k8s⾃动搭建⼀个数据库</p><p>则开启&quot;基于yaml创建资源&quot;按钮，默认的yaml会创建⼀个pv进⾏mysql的数据存储，如果沿⽤默 认的yaml，⼀定要注意：</p><ol><li>提前在宿主机node上创建⽬录/opt/ozhera_pv/ozhera_mysql（可更换⽬录，同步修改此处yaml）；</li><li>找到创建⽬录的node名（可以执⾏ kubectl get node进⾏确认），替换此处的cn-bxxx52；</li><li>连接信息确保与yaml中信息⼀致，默认⽆需修改。</li></ol></li></ul><p><img src="'+p+'" alt="ozhera-mysql.jpg"></p><ul><li>如果已有数据库，⽆需k8s创建 <ol><li>关闭&quot;基于yaml创建资源&quot;按钮；</li><li>填写正确的已有数据库url、⽤⼾名、密码；</li><li>默认operator执⾏时会⾃动去改数据库进⾏创建ozhera数据库及表，<strong>如果填写的账号⽆建库、建表权限，则需提前⼿动去⽬标库中建好ozhera数据库和表</strong>，建表语句在operator源码ozhera-all/ozhera-operator/ozheraoperator-server/src/main/resources/ozhera_init/mysql/sql ⽬录下。</li></ol></li></ul><p><img src="'+s+'" alt="ozhera-mysql2.jpg"></p><h5 id="ozhera-es" tabindex="-1">OzHera-es <a class="header-anchor" href="#ozhera-es" aria-label="Permalink to &quot;OzHera-es&quot;">​</a></h5><p>⽬的是选择⼀个OzHera可⽤的ES集群，并在ES中创建OzHera所需要的索引模板。</p><ul><li><p>如果需要k8s⾃动搭建⼀个ES</p><p>则需要开启“基于yaml创建资源”按钮。使⽤默认yaml创建的ES没有账号密码，如果需要设置账号密码，则需要：</p><ol><li>修改左侧yaml中的xpack.security.enabled为true；</li><li>修改右侧“连接信息”中的ozhera.es.username与ozhera.es.password的值，⼀般地，我们都会⽤elastic的账号，密码需要在ES服务启动后进⾏设置；</li><li>在ES启动后，登⼊ES所在pod中，进⼊/usr/share/elasticsearch/bin⽬录执⾏elasticsearchsetup-passwords interactive命令，设置ES默认账号的密码，注意，这⾥设置的密码，需要与⻚⾯ozhera.es.password的值保持⼀致。</li></ol></li></ul><p><img src="'+t+'" alt="ozhera-es.jpg"></p><ul><li>如果已有ES，⽆需k8s创建 <ol><li>关闭&quot;基于yaml创建资源&quot;按钮；</li><li>填写正确的已有ES集群的url、账号、密码；</li><li>默认operator执⾏时会⾃动创建索引模版。<strong>如果填写的账号⽆创建索引模版的权限，则需要提前⼿动创建OzHera所需要的索引模版</strong>。OzHera的索引模版在operator源码run.mone.ozhera.operator.common.ESIndexConst中，以json的格式存储。</li></ol></li></ul><p><img src="'+i+'" alt="ozhera-es2.jpg"></p><h5 id="ozhera-rocketmq" tabindex="-1">OzHera-rocketMQ <a class="header-anchor" href="#ozhera-rocketmq" aria-label="Permalink to &quot;OzHera-rocketMQ&quot;">​</a></h5><p>⽬的是选择⼀个ozhera可⽤的RocketMQ</p><ul><li>如果需要k8s⾃动搭建⼀个RocketMQ <ol><li>需要开启“基于yaml创建资源”按钮；</li><li>使⽤默认yaml创建的RocketMQ没有accessKey\\secretKey，如果需要设置accessKey\\secretKey，则需要修改右侧“连接信息”中的ozhera.rocketmq.ak与ozhera.rocketmq.sk的值；</li><li>如果需要更换RocketMQ broker的service，需要同时替换yaml中的service，以及ozoperator代码中的run.mone.ozhera.operator.service.RocketMQSerivce类的成员变量&quot;brokerAddr&quot;的值。</li></ol></li></ul><p><img src="'+c+'" alt="ozhera-rocketmq.jpg"></p><ul><li>如果已有RocketMQ，⽆需k8s搭建 <ol><li>关闭&quot;基于yaml创建资源&quot;按钮；</li><li>填写正确的已有RocketMQ集群的url、accessKey、secretKey；</li><li>默认operator执⾏时会⾃动创建OzHera所需要的topic。<strong>如果填写的url、ak、sk没有权限创建topic，或者已有RocketMQ集群不允许通过API创建topic，则需要提前⼿动创建好topic</strong>。OzHera需要的topic在operator源码run.mone.ozhera.operator.service.RocketMQSerivce类的成员变量&quot;topics&quot;中存储。</li></ol></li></ul><p><img src="'+n+'" alt="ozhera-rocketmq2.jpg"></p><h5 id="ozhera-redis" tabindex="-1">OzHera-redis <a class="header-anchor" href="#ozhera-redis" aria-label="Permalink to &quot;OzHera-redis&quot;">​</a></h5><p>⽬的是选择⼀个ozhera可⽤的Redis</p><ul><li><p>如果需要k8s⾃动搭建⼀个Redis</p><p>则需要开启“基于yaml创建资源”按钮。使⽤默认yaml创建的redis没有密码，如果需要设置密码，则需要修改右侧ozhera.redis.password的值，与redis设置的密码保持⼀致。</p></li></ul><p><img src="'+h+'" alt="ozhera-redis.jpg"></p><ul><li>如果已有Redis，⽆需k8s搭建 <ol><li>关闭&quot;基于yaml创建资源&quot;按钮；</li><li>填写正确的已有Redis集群的URL、密码。</li></ol></li></ul><p><img src="'+m+'" alt="ozhera-redis2.jpg"></p><h5 id="ozhera-nacos" tabindex="-1">OzHera-Nacos <a class="header-anchor" href="#ozhera-nacos" aria-label="Permalink to &quot;OzHera-Nacos&quot;">​</a></h5><p>ozhera集群内部的配置、注册中⼼，该集群建议⾛yaml创建⽅式，如果业务需要⾃⾏提供Nacos，请优先提供1.x版本的Nacos。</p><ul><li><p>如果需要k8s⾃动搭建⼀个Nacos</p><p>则需要开启“基于yaml创建资源”按钮，注意yaml中的镜像地址、资源⼤⼩配置及右侧连接信息与yaml中保持⼀致。</p></li></ul><p><img src="'+d+'" alt="ozhera-nacos.jpg"></p><ul><li><p>如果已有Nacos，⽆需k8s创建</p><p>则需关闭“基于yaml创建资源”按钮，填写正确的nacos连接信息。</p></li></ul><p><img src="'+u+'" alt="ozhera-nacos2.jpg"></p><ul><li><p>Nacos配置</p><p>operator会默认将这⾥所列的配置初始化为nacos配置，如果提供的不是基于yaml所创建的nacos，请确认连接信息有权限调⽤config创建接⼝，否则需要提前去⽬标nacos中⼿动创建好。</p></li></ul><p><img src="'+z+'" alt="ozhera-nacos3.jpg"></p><h5 id="ozhera-prometheus" tabindex="-1">OzHera-Prometheus <a class="header-anchor" href="#ozhera-prometheus" aria-label="Permalink to &quot;OzHera-Prometheus&quot;">​</a></h5><p>⽬的是选择⼀个ozhera可⽤的prometheus。</p><p>如果沿⽤默认的yaml，⼀定要注意：</p><ul><li>提前在宿主机node上创建⽬录/home/work/prometheus_ozhera_namespace_pv;</li><li>找到创建⽬录的node名（可以执⾏ kubectl get node进⾏确认），替换此处的cn- xxx。</li></ul><p><img src="'+g+'" alt="ozhera-prometheus.jpg"></p><h5 id="ozhera-alertmanager" tabindex="-1">OzHera-Alertmanager <a class="header-anchor" href="#ozhera-alertmanager" aria-label="Permalink to &quot;OzHera-Alertmanager&quot;">​</a></h5><p>⽬的是选择⼀个ozhera可⽤的alertmanager。</p><p>如果沿⽤默认的yaml，⼀定要注意：</p><ul><li>提前在宿主机node上创建⽬录/home/work/alertmanager_ozhera_namespace_pv；</li><li>找到创建⽬录的node名（可以执⾏ kubectl get node进⾏确认），替换此处的cn-。</li></ul><p><img src="'+_+'" alt="ozhera-alertmanager.jpg"></p><h5 id="ozhera-grafana" tabindex="-1">OzHera-Grafana <a class="header-anchor" href="#ozhera-grafana" aria-label="Permalink to &quot;OzHera-Grafana&quot;">​</a></h5><p>⽬的是选择⼀个ozhera可⽤的grafana。</p><p>如果沿⽤默认的yaml，⼀定要注意：</p><ul><li>提前在宿主机node上创建⽬录/home/work/grafana_ozhera_namespace_pv；</li><li>找到创建⽬录的node名（可以执⾏ kubectl get node进⾏确认），替换此处的cn- beijingxxx；</li><li>在OzHera-mysql中配置的host、user、port、password等内容需要在ozhera-grafana的相应db配置中进⾏覆盖。</li></ul><p><img src="'+y+'" alt="ozhera-grafana.jpg"></p><p><img src="'+k+'" alt="ozhera-grafana2.jpg"></p><h5 id="ozhera-node-exporter" tabindex="-1">OzHera-Node-exporter <a class="header-anchor" href="#ozhera-node-exporter" aria-label="Permalink to &quot;OzHera-Node-exporter&quot;">​</a></h5><p>⽬的是选择⼀个ozhera可⽤的node-exporter。</p><p>如果沿⽤默认的yaml，⼀定要注意：</p><ul><li>提前在宿主机找到⼀个可⽤Port，并填⼊下图中的hostPort处，默认为9101，修改完成后，同步更新右侧连接信息中的mione.k8s.node.port内容。</li></ul><p><img src="'+b+'" alt="ozhera-node-exporter.jpg"></p><h5 id="ozhera-cadvisor" tabindex="-1">OzHera-Cadvisor <a class="header-anchor" href="#ozhera-cadvisor" aria-label="Permalink to &quot;OzHera-Cadvisor&quot;">​</a></h5><p>⽬的是选择⼀个ozhera可⽤的cadvisor。</p><p>如果沿⽤默认的yaml，⼀定要注意：</p><ul><li>提前在宿主机找到⼀个可⽤Port，并填⼊下图中的hostPort处，默认为5195，修改后同步更新右侧连接信息中的mione.k8s.container.port内容。</li></ul><p><img src="'+q+'" alt="ozhera-cadvisor.jpg"></p><h5 id="ozhera-trace-etl-es" tabindex="-1">OzHera-trace-etl-es <a class="header-anchor" href="#ozhera-trace-etl-es" aria-label="Permalink to &quot;OzHera-trace-etl-es&quot;">​</a></h5><p>需要注意的是：</p><ul><li>该服务是StatefulSet类型服务；</li><li>提前在宿主机node上创建⽬录/home/work/rocksdb（可更换⽬录，同步修改此处yaml）；</li><li>找到创建⽬录的node名（可以执⾏ kubectl get node进⾏确认），替换此处的nodeSelectorTerms下的values的值；</li><li>需要根据trace流量来修改pod副本数(replicas)与pod资源限制(resources)；</li><li>服务的pod副本数尽量与RocketMQ的queue size保持⼀致。</li></ul><p><img src="'+f+'" alt="ozhera-trace-etl-es.jpg"></p><h5 id="ozhera-trace-etl-manager" tabindex="-1">OzHera-trace-etl-manager <a class="header-anchor" href="#ozhera-trace-etl-manager" aria-label="Permalink to &quot;OzHera-trace-etl-manager&quot;">​</a></h5><p>需要注意的是：</p><ul><li>需要根据访问量来修改pod副本数(replicas)与pod资源限制(resources)。</li></ul><p><img src="'+E+'" alt="ozhera-trace-etl-manager.jpg"></p><h5 id="ozhera-trace-etl-server" tabindex="-1">OzHera-trace-etl-server <a class="header-anchor" href="#ozhera-trace-etl-server" aria-label="Permalink to &quot;OzHera-trace-etl-server&quot;">​</a></h5><p>需要注意的是：</p><ul><li>需要根据访问量来修改pod副本数(replicas)与pod资源限制(resources)</li><li>服务的pod副本数需要与RocketMQ的queue size保持⼀致</li></ul><p><img src="'+v+'" alt="ozhera-trace-etl-server.jpg"></p><h5 id="ozhera-monitor" tabindex="-1">OzHera-monitor <a class="header-anchor" href="#ozhera-monitor" aria-label="Permalink to &quot;OzHera-monitor&quot;">​</a></h5><p>ozhera-monitor是hera监控⾸⻚应⽤中⼼、指标监控、报警配置的后端服务，建议直接使⽤operator提供的基于yaml创建资源的⽅式部署。当然，也可以⾃⾏部署ozhera-monitor服务（关闭给予yaml资源创建的开关），⾃⼰部署服务，需要调整前端对接的相应参数：如ip地址、端⼝号等。</p><p>需要注意的是：</p><ul><li><p>MySQL</p><p>在nacos配置MySQL的数据库，在对应的数据库名下按照ozhera-all/ozhera-monitor/sql ⽂件初始化数据库表。</p></li><li><p>RocketMQ</p><p>按照nacos上的配置，在对应的RocketMQ服务器上创建mq相应的topic和tag。</p></li><li><p>ES</p><p>按照nacos上的配置，在对应的ES服务器上创建es相应的索引。</p></li><li><p>使⽤operator⾃动创建资源，可以根据⾃⼰的实际流量情况调整副本数，replicas。实例中是⼀个副本；同样，可是根据需要在operator的yaml⽂件中调整k8s相关的资源，如 cpu、memory。</p></li></ul><p><img src="'+x+'" alt="ozhera-monitor.jpg"></p><h5 id="ozhera-fe" tabindex="-1">OzHera-fe <a class="header-anchor" href="#ozhera-fe" aria-label="Permalink to &quot;OzHera-fe&quot;">​</a></h5><p>ozhera-fe是负责构建ozhera前端⻚⾯的yaml。</p><p>需要注意的是：</p><ul><li>需要根据访问量来修改pod副本数(replicas)与pod资源限制(resources)。</li></ul><p><img src="'+O+'" alt="ozhera-fe.jpg"></p><h5 id="ozhera-tpc-login" tabindex="-1">OzHera-tpc-login <a class="header-anchor" href="#ozhera-tpc-login" aria-label="Permalink to &quot;OzHera-tpc-login&quot;">​</a></h5><p>ozhera-tpc-login是负责构建tpclogin登陆服务后端的yaml。</p><p>需要注意的是：</p><ul><li>需要根据访问量来修改pod副本数(replicas)与pod资源限制(resources)；</li><li>服务启动的配置像个信息在上⽅的nacos配置中。</li></ul><p><img src="'+P+'" alt="ozhera-tpc.jpg"></p><h5 id="ozhera-tpc-login-fe" tabindex="-1">OzHera-tpc-login-fe <a class="header-anchor" href="#ozhera-tpc-login-fe" aria-label="Permalink to &quot;OzHera-tpc-login-fe&quot;">​</a></h5><p>ozhera-tpc-login-fe是负责构建tpclogin登录前端⻚⾯的yaml。</p><p>需要注意的是：</p><ul><li>需要根据访问量来修改pod副本数(replicas)与pod资源限制(resources)。</li></ul><p><img src="'+H+'" alt="ozhera-tpc-login-fe.jpg"></p><h5 id="ozhera-tpc" tabindex="-1">OzHera-tpc <a class="header-anchor" href="#ozhera-tpc" aria-label="Permalink to &quot;OzHera-tpc&quot;">​</a></h5><p>ozhera-tpc是负责构建tpc服务后端的yaml。</p><p>需要注意的是：</p><ul><li>需要根据访问量来修改pod副本数(replicas)与pod资源限制(resources)；</li><li>服务相关配置在上⽅的nacos配置中配置。</li></ul><p><img src="'+F+'" alt="ozhera-tpc.jpg"></p><h5 id="ozhera-tpc-fe" tabindex="-1">OzHera-tpc-fe <a class="header-anchor" href="#ozhera-tpc-fe" aria-label="Permalink to &quot;OzHera-tpc-fe&quot;">​</a></h5><p>ozhera-tpc-fe是负责构建tpc前端⻚⾯的yaml。</p><p>需要注意的是：</p><ul><li>需要根据访问量来修改pod副本数(replicas)与pod资源限制(resources)。</li></ul><p><img src="'+C+'" alt="ozhera-tpc-fe.jpg"></p><h5 id="ozhera-app" tabindex="-1">OzHera-app <a class="header-anchor" href="#ozhera-app" aria-label="Permalink to &quot;OzHera-app&quot;">​</a></h5><p>ozhera-app是负责负责hera系统中应⽤app相关逻辑操作，可以通过这个服务向外提供对应⽤的各种服务信息。</p><p>需要注意的是：</p><ul><li>需要根据访问量来修改pod副本数(replicas)与pod资源限制(resources)。</li></ul><p><img src="'+j+'" alt="ozhera-app.jpg"></p><h5 id="ozhera-log-manager" tabindex="-1">OzHera-log-manager <a class="header-anchor" href="#ozhera-log-manager" aria-label="Permalink to &quot;OzHera-log-manager&quot;">​</a></h5><p>ozhera-log-manager主要负责⻚⾯应⽤⽇志的接⼊，以及各种元数据的配置下发。</p><p>需要注意的是：</p><ul><li>由于该服务需要对外提供http服务，因此需要开⼀个端⼝，端⼝默认来⾃与项⽬中的配置⽂件，默认为7788。</li></ul><p><img src="'+S+'" alt="ozhera-log-manager.jpg"></p><h5 id="ozhera-log-stream" tabindex="-1">OzHera-log-stream <a class="header-anchor" href="#ozhera-log-stream" aria-label="Permalink to &quot;OzHera-log-stream&quot;">​</a></h5><p>ozhera-log-stream负责消费mq中的应⽤⽇志信息，然后负责应⽤⽇志解析，最后存⼊存储空间(ES)。</p><p>需要注意的是：</p><ul><li>该服务是StatefulSet类型服务；</li><li>需要注⼊⼀个环境变量MONE_CONTAINER_S_POD_NAME，值为容器pod的名称。</li></ul><p><img src="'+Q+'" alt="ozhera-log-stream.jpg"></p><h4 id="_2-4-5-集群部署" tabindex="-1">2.4.5 集群部署 <a class="header-anchor" href="#_2-4-5-集群部署" aria-label="Permalink to &quot;2.4.5 集群部署&quot;">​</a></h4><ul><li><p>保存配置</p><p>确保2.4.4步骤完毕后，点击保存配置，该步骤会完成:</p><ol><li>整个配置的保持；</li><li>nacos变量替换（nacos配置中有${变量}配置的，会⾃动完成⼀轮替换，替换值来源于输⼊的连接信息、第⼆步⽣成的访问⽅式 ip:port）。</li></ol></li><li><p>集群⽣效</p><p>确保&quot;保存配置&quot;已完成后，可点击&quot;集群⽣效&quot;进⾏整个hera集群的部署。</p></li></ul>',150),T=[A];function L(D,I,K,$,V,G){return M(),R("div",null,T)}const W=B(w,[["render",L]]);export{U as __pageData,W as default};
